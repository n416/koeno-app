import React, { useState, useRef } from 'react'; // â˜… AudioInput ã®ãŸã‚ã« useState/useRef ãŒå¿…è¦
import './App.css';

// â˜… 1. Reduxãƒ•ãƒƒã‚¯ã¨Actionã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import { useAppDispatch, useAppSelector } from './store/hooks';
import { 
  setStatus, 
  setTargetVoice, 
  setTestAudio, 
  setTranscription, 
  setError, 
  resetApiState 
} from './store/appSlice';

// APIã‹ã‚‰è¿”ã£ã¦ãã‚‹JSONã®å‹
interface TranscriptionSegment {
  speaker: 'TARGET' | 'OTHER';
  start: number;
  end: number;
  text: string;
}

// APIã‚µãƒ¼ãƒãƒ¼ã®URL
const API_URL = "http://127.0.0.1:8000/transcribe";


// â˜…â˜…â˜…â˜…â˜… AudioInput ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ â˜…â˜…â˜…â˜…â˜…
// -----------------------------------------------------------
interface AudioInputProps {
  title: string;
  fileId: string; // (target_voice / mixed_audio)
  onFileSelect: (file: Blob, fileName: string) => void;
  selectedFileName: string | null;
  disabled: boolean;
}

/**
 * éŒ²éŸ³æ©Ÿèƒ½ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’æ‹…å½“ã™ã‚‹UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
 */
const AudioInput: React.FC<AudioInputProps> = ({ title, fileId, onFileSelect, selectedFileName, disabled }) => {
  const [isRecording, setIsRecording] = useState(false);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  // â˜… ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ (<input type="file">) ã®å‡¦ç†
  const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (file) {
      onFileSelect(file, file.name);
    }
    event.target.value = '';
  };

  // â˜… éŒ²éŸ³é–‹å§‹
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const recorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
      mediaRecorderRef.current = recorder;
      audioChunksRef.current = [];

      recorder.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data);
      };

      recorder.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        onFileSelect(audioBlob, `${fileId}_recorded.webm`);
        setIsRecording(false);
        stream.getTracks().forEach(track => track.stop());
      };

      recorder.start();
      setIsRecording(true);
    } catch (err) {
      alert("ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ãŒå¿…è¦ã§ã™ã€‚");
      console.error(err);
    }
  };

  // â˜… éŒ²éŸ³åœæ­¢
  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }
  };

  return (
    <section>
      <h3>{title}</h3>
      <div style={{ display: 'flex', gap: '10px', alignItems: 'center' }}>
        {/* éŒ²éŸ³ãƒœã‚¿ãƒ³ */}
        {!isRecording ? (
          <button onClick={startRecording} disabled={disabled}>
            ğŸ¤ éŒ²éŸ³é–‹å§‹
          </button>
        ) : (
          <button onClick={stopRecording} style={{ color: 'red' }}>
            â–  éŒ²éŸ³åœæ­¢
          </button>
        )}

        <span>ã¾ãŸã¯</span>

        {/* ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ */}
        <label htmlFor={`${fileId}-upload`} className="custom-file-upload" style={{
            backgroundColor: '#f0f0f0',
            border: '1px solid #ccc',
            padding: '6px 12px',
            borderRadius: '4px',
            cursor: disabled ? 'not-allowed' : 'pointer',
            opacity: disabled ? 0.5 : 1
        }}>
          ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
        </label>
        <input 
          id={`${fileId}-upload`}
          type="file" 
          accept="audio/*" // .webm, .mp3, .wav ãªã©
          onChange={handleFileChange}
          style={{ display: 'none' }} // inputã‚¿ã‚°è‡ªä½“ã¯éš ã™
          disabled={disabled}
        />
      </div>
      {selectedFileName && (
        <p style={{ color: 'green' }}>âœ… æº–å‚™OK: {selectedFileName}</p>
      )}
    </section>
  );
};
// -----------------------------------------------------------
// â˜…â˜…â˜…â˜…â˜… AudioInput ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã“ã“ã¾ã§ â˜…â˜…â˜…â˜…â˜…


/**
 * ãƒ¡ã‚¤ãƒ³ã®Appã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆReduxã§çŠ¶æ…‹ç®¡ç†ï¼‰
 */
function App() {
  // â˜… 2. Redux ã‹ã‚‰ State ã‚’å–å¾—
  const dispatch = useAppDispatch();
  const { 
    status, 
    targetVoice, 
    testAudio, 
    transcription, 
    error 
  } = useAppSelector((state) => state.app);

  
  // --- 3. APIã‚µãƒ¼ãƒãƒ¼ã¸é€ä¿¡ (fetch) ---
  const handleSubmit = async () => {
    if (!targetVoice.blob || !testAudio.blob) {
      dispatch(setError("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å£°ã¨ä¼šè©±éŒ²éŸ³ã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™ã€‚"));
      return;
    }
    
    dispatch(resetApiState());
    dispatch(setStatus('loading'));

    const formData = new FormData();
    formData.append('target_voice', targetVoice.blob, targetVoice.name || 'target_voice.webm');
    formData.append('mixed_audio', testAudio.blob, testAudio.name || 'test_audio.webm');

    try {
      const response = await fetch(API_URL, {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        const errData = await response.json();
        throw new Error(errData.detail || `HTTPã‚¨ãƒ©ãƒ¼: ${response.status}`);
      }

      const result = await response.json();
      dispatch(setTranscription(result.transcription as TranscriptionSegment[]));
      dispatch(setStatus('success'));
      console.log("API æˆåŠŸ:", result);

    } catch (err) {
      console.error("API å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼:", err);
      dispatch(setError(err instanceof Error ? err.message : "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"));
      dispatch(setStatus('idle'));
    }
  };

  const isLoading = status === 'loading';

  return (
    <div className="App">
      <header className="App-header">
        <h1>ã‚¹ãƒ†ãƒƒãƒ—2b: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ (Reduxå¯¾å¿œ)</h1>
        
        {/* ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŒ²éŸ³ãƒ»é¸æŠ */}
        <AudioInput
          title="1. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å£°ã‚’ç™»éŒ²"
          fileId="target_voice" //
          onFileSelect={(blob, name) => dispatch(setTargetVoice({ blob, name }))}
          selectedFileName={targetVoice.name}
          disabled={isLoading}
        />

        {/* ã‚¹ãƒ†ãƒƒãƒ—2: ä¼šè©±éŒ²éŸ³ãƒ»é¸æŠ */}
        <AudioInput
          title="2. ä¼šè©±ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‹ä»–äººï¼‰ã‚’éŒ²éŸ³"
          fileId="mixed_audio" //
          onFileSelect={(blob, name) => dispatch(setTestAudio({ blob, name }))}
          selectedFileName={testAudio.name}
          disabled={isLoading}
        />

        {/* ã‚¹ãƒ†ãƒƒãƒ—3: å®Ÿè¡Œ */}
        <section>
          <h3>3. APIå®Ÿè¡Œ</h3>
          <button 
            onClick={handleSubmit}
            disabled={!targetVoice.blob || !testAudio.blob || isLoading}
            style={{ fontSize: '1.2em', padding: '10px 20px' }}
          >
            {isLoading ? "AIå‡¦ç†ä¸­..." : "åˆ†é›¢ãƒ»æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ"}
          </button>
        </section> 
        {/* â˜…â˜…â˜…â˜…â˜… ã“ã“ãŒä¿®æ­£ç‚¹ â˜…â˜…â˜…â˜…â˜…
            ( '> </section> ' ã® '>' ãŒæŠœã‘ã¦ã„ãŸã®ã‚’ä¿®æ­£)
        */}

        {/* ã‚¹ãƒ†ãƒƒãƒ—4: çµæœ */}
        <section>
          <h3>4. ã‚«ãƒ«ãƒ†çµæœ</h3>
          {error && <p style={{ color: 'red' }}>ã‚¨ãƒ©ãƒ¼: {error}</p>}
          {status === 'success' && transcription.length === 0 && (
            <p>ï¼ˆæ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰</p>
          )}
          <div style={{ textAlign: 'left', maxWidth: '600px', margin: 'auto' }}>
            {transcription.map((segment, index) => (
              <p key={index} style={{ 
                  color: segment.speaker === 'TARGET' ? '#007bff' : '#28a745',
                  fontWeight: segment.speaker === 'TARGET' ? 'bold' : 'normal' 
                }}>
                [{segment.speaker}] ({segment.start}s - {segment.end}s): {segment.text}
              </p>
            ))}
          </div>
        </section>
      </header>
    </div>
  );
}

export default App;